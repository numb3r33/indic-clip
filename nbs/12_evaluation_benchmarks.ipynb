{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e009a6a-b90e-4550-94e0-1ff9e37302b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation.benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b18888-27ac-45d7-8b88-87e3f803c5a4",
   "metadata": {},
   "source": [
    "# Evaluation Benchmarks\n",
    "\n",
    "> Setup for evaluation datasets and DataLoaders. Defines Indic-specific categories and provides functions to load benchmark data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf5191-ab5f-416f-9625-5d52e5f786c7",
   "metadata": {},
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c2273-5a53-4ac1-9dfc-20524c430ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Mount Google Drive (Optional, but recommended for persistent storage)\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully.\")\n",
    "    # Define PROJECT_ROOT for Colab\n",
    "    PROJECT_ROOT = Path('/content/drive/MyDrive/Indic-Clip') # Adjust path if needed\n",
    "    if not PROJECT_ROOT.exists():\n",
    "        print(f\"Warning: Project directory not found at {PROJECT_ROOT}. Please ensure it exists.\")\n",
    "    else:\n",
    "        # Add project root to sys.path\n",
    "        if str(PROJECT_ROOT) not in sys.path:\n",
    "            sys.path.insert(0, str(PROJECT_ROOT))\n",
    "            print(f\"Added {PROJECT_ROOT} to sys.path\")\n",
    "        # Change current working directory\n",
    "        os.chdir(PROJECT_ROOT)\n",
    "        print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Not running in Colab, skipping Drive mount.\")\n",
    "    # Define PROJECT_ROOT for local execution (adjust if needed)\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "    if PROJECT_ROOT.name == 'nbs': PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "    print(f\"Running locally. Project root assumed: {PROJECT_ROOT}\")\n",
    "    if str(PROJECT_ROOT) not in sys.path:\n",
    "         sys.path.insert(0, str(PROJECT_ROOT))\n",
    "         print(f\"Added {PROJECT_ROOT} to sys.path\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Colab setup: {e}\")\n",
    "    PROJECT_ROOT = Path('.').resolve()\n",
    "    print(f\"Defaulting project root to current dir: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a53ef-2b6e-44f8-9a67-a446a7b4a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Install requirements if needed (especially in Colab)\n",
    "# !pip install -qr requirements.txt\n",
    "# !pip install scikit-learn # Ensure sklearn is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6c118-f97d-41d2-9a40-891d3c35ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d91c25-f472-47f6-849a-e1f79f37ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union, Callable\n",
    "\n",
    "from fastai.vision.all import (\n",
    "    DataBlock, ImageBlock, CategoryBlock, ColReader, RandomSplitter,\n",
    "    Resize, Normalize, imagenet_stats, DataLoader, Datasets, TfmdLists\n",
    ")\n",
    "from fastcore.all import *\n",
    "\n",
    "# --- Project Imports ---\n",
    "try:\n",
    "    from indic_clip.core import (\n",
    "        get_logger, setup_logging, BENCHMARK_DATA_PATH, DEFAULT_IMAGE_SIZE,\n",
    "        HINDI_RAW_PATH, SANSKRIT_RAW_PATH # Needed if benchmark images are in raw dirs\n",
    "    )\n",
    "    from indic_clip.data.creation import ImageGetter # Reuse image getter if structure is same\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Could not import project modules in 12_evaluation_benchmarks.ipynb. Using fallbacks.\")\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    def get_logger(name): return logging.getLogger(name)\n",
    "    def setup_logging(): pass\n",
    "    BENCHMARK_DATA_PATH = Path('./data/benchmarks')\n",
    "    DEFAULT_IMAGE_SIZE = 224\n",
    "    HINDI_RAW_PATH = Path('./data/raw/hindi')\n",
    "    SANSKRIT_RAW_PATH = Path('./data/raw/sanskrit')\n",
    "    # Dummy ImageGetter if needed\n",
    "    def ImageGetter(row): return BENCHMARK_DATA_PATH / 'dummy_image.jpg'\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d418d-7f1c-446f-9290-500279907165",
   "metadata": {},
   "source": [
    "## Indic-Specific Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d03e99-828b-4346-aa39-7cc2e3f50c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# --- Example Indic Categories for Zero-Shot Classification ---\n",
    "# These lists should be curated based on expected evaluation domains.\n",
    "# Hindi\n",
    "HINDI_RELIGIOUS_FIGURES = [\n",
    "    \"कृष्ण\", \"राम\", \"शिव\", \"गणेश\", \"हनुमान\", \"दुर्गा\", \"लक्ष्मी\", \"सरस्वती\", \"विष्णु\", \"बुद्ध\", \"महावीर\"\n",
    "]\n",
    "HINDI_ECOMMERCE_CATEGORIES = [\n",
    "    \"साड़ी\", \"कुर्ता\", \"मोबाइल फोन\", \"जूते\", \"किताब\", \"घड़ी\", \"चश्मा\", \"हेडफ़ोन\", \"लैपटॉप\", \"कैमरा\", \"गहने\"\n",
    "]\n",
    "\n",
    "# Sanskrit (Example - adjust based on available data/domain)\n",
    "SANSKRIT_RELIGIOUS_CONCEPTS = [\n",
    "    \"देव\", \"देवी\", \"यज्ञ\", \"मन्त्र\", \"वेद\", \"उपनिषद्\", \"पुराण\", \"योग\", \"ध्यान\", \"धर्म\", \"कर्म\"\n",
    "]\n",
    "\n",
    "# Combine or select based on evaluation needs\n",
    "DEFAULT_ZS_CATEGORIES_HI = HINDI_RELIGIOUS_FIGURES + HINDI_ECOMMERCE_CATEGORIES\n",
    "DEFAULT_ZS_CATEGORIES_SA = SANSKRIT_RELIGIOUS_CONCEPTS\n",
    "\n",
    "# --- Example Prompt Templates --- (Use appropriate language)\n",
    "DEFAULT_PROMPT_TEMPLATES_HI = [\n",
    "    \"यह {} की तस्वीर है।\",\n",
    "    \"{} का एक चित्र।\",\n",
    "    \"एक फोटो जिसमें {} दिखाया गया है।\"\n",
    "]\n",
    "DEFAULT_PROMPT_TEMPLATES_SA = [\n",
    "    \"इदं {} चित्रम् अस्ति।\",\n",
    "    \"{} एकं चित्रम्।\"\n",
    "]\n",
    "DEFAULT_PROMPT_TEMPLATES_EN = [\n",
    "    \"a photo of a {}\",\n",
    "    \"a picture of {}\",\n",
    "    \"an image depicting {}\",\n",
    "    \"{} shown in an image\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c698a50-e91c-4588-8771-be03f15cd650",
   "metadata": {},
   "source": [
    "## Benchmark Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4e25c-e991-4154-9a62-780dfc6a5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_benchmark_data(benchmark_name: str, base_path: Path = BENCHMARK_DATA_PATH) -> pd.DataFrame | None:\n",
    "    \"\"\"Loads image paths and labels for a specific benchmark dataset.\n",
    "       Assumes a standard format (e.g., CSV/JSONL) within the benchmark directory.\n",
    "\n",
    "    Args:\n",
    "        benchmark_name (str): Name of the benchmark (e.g., 'imagenet_val', 'flickr30k_hi').\n",
    "        base_path (Path): Base directory containing benchmark subdirectories.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns like 'image_path', 'label' (or 'captions'), 'split'.\n",
    "                      Returns None if loading fails or format is unknown.\n",
    "    \"\"\"\n",
    "    benchmark_dir = base_path / benchmark_name\n",
    "    logger.info(f\"Attempting to load benchmark data from: {benchmark_dir}\")\n",
    "\n",
    "    if not benchmark_dir.is_dir():\n",
    "        logger.error(f\"Benchmark directory not found: {benchmark_dir}\")\n",
    "        return None\n",
    "\n",
    "    # --- Example Loading Logic (Adapt based on actual benchmark formats) ---\n",
    "\n",
    "    # Example 1: CSV format (e.g., image_path,label_id,split)\n",
    "    csv_file = benchmark_dir / f\"{benchmark_name}.csv\"\n",
    "    if csv_file.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # Basic validation (adjust columns as needed)\n",
    "            if 'image_path' not in df.columns or ('label' not in df.columns and 'caption' not in df.columns):\n",
    "                logger.error(f\"CSV {csv_file} missing required columns ('image_path' and 'label'/'caption'). Found: {df.columns}\")\n",
    "                return None\n",
    "            logger.info(f\"Loaded {len(df)} items from CSV: {csv_file}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading CSV benchmark data from {csv_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Example 2: JSONL format (e.g., {'image_path': '...', 'label': '...', 'split': '...'})\n",
    "    jsonl_file = benchmark_dir / f\"{benchmark_name}.jsonl\"\n",
    "    if jsonl_file.exists():\n",
    "        data = []\n",
    "        try:\n",
    "            with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    item = json.loads(line)\n",
    "                    # Add validation for required keys\n",
    "                    if 'image_path' in item and ('label' in item or 'caption' in item):\n",
    "                        data.append(item)\n",
    "                    else:\n",
    "                        logger.warning(f\"Skipping invalid item in {jsonl_file}: {item}\")\n",
    "            df = pd.DataFrame(data)\n",
    "            logger.info(f\"Loaded {len(df)} items from JSONL: {jsonl_file}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading JSONL benchmark data from {jsonl_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # --- Add more loading logic for other formats --- (e.g., ImageFolder structure)\n",
    "\n",
    "    logger.error(f\"Could not find suitable data file (CSV/JSONL) in {benchmark_dir} for benchmark '{benchmark_name}'.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fef335-e670-4740-806d-070a711c01e3",
   "metadata": {},
   "source": [
    "## DataLoader Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9276f1-ef9d-4a50-9351-e8a867875538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_zeroshot_dataloader(\n",
    "    df: pd.DataFrame,\n",
    "    image_path_col: str = 'image_path',\n",
    "    label_col: str = 'label',\n",
    "    benchmark_base_path: Path = BENCHMARK_DATA_PATH,\n",
    "    img_size: int = DEFAULT_IMAGE_SIZE,\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 4\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Creates a DataLoader for zero-shot classification evaluation.\n",
    "\n",
    "    The DataLoader yields tuples of (image_tensor, label_index).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and corresponding labels (indices).\n",
    "        image_path_col (str): Name of the column containing relative image paths.\n",
    "        label_col (str): Name of the column containing ground truth labels (as indices).\n",
    "        benchmark_base_path (Path): The absolute base path where the benchmark images are stored.\n",
    "                                      The paths in df[image_path_col] are assumed relative to this.\n",
    "        img_size (int): Target image size.\n",
    "        batch_size (int): DataLoader batch size.\n",
    "        num_workers (int): Number of workers for the DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A fastai DataLoader for evaluation, or None if columns are missing.\n",
    "    \"\"\"\n",
    "    if image_path_col not in df.columns or label_col not in df.columns:\n",
    "        logger.error(f\"Required columns '{image_path_col}' or '{label_col}' not found in DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    # Function to construct the full image path\n",
    "    def get_img_path(row): return benchmark_base_path / row[image_path_col]\n",
    "\n",
    "    # Define a simple DataBlock for loading images and labels\n",
    "    # No splitting needed as we evaluate on the whole set (usually test set)\n",
    "    # Use TfmdLists directly for more control over evaluation datasets\n",
    "\n",
    "    # 1. Create item transforms (Resize)\n",
    "    item_tfms = Resize(img_size)\n",
    "    # 2. Create batch transforms (Normalize)\n",
    "    batch_tfms = Normalize.from_stats(*imagenet_stats)\n",
    "\n",
    "    # 3. Create Datasets\n",
    "    # We need image paths and integer labels\n",
    "    img_paths = df.apply(get_img_path, axis=1).tolist()\n",
    "    labels = df[label_col].tolist()\n",
    "\n",
    "    # Ensure labels are integers\n",
    "    try:\n",
    "        labels = [int(l) for l in labels]\n",
    "    except ValueError:\n",
    "        logger.error(f\"Could not convert all labels in column '{label_col}' to integers.\")\n",
    "        return None\n",
    "\n",
    "    # Create TfmdLists: applies item_tfms lazily\n",
    "    # Input pipeline: Path -> Image -> PILImage\n",
    "    # Target pipeline: int -> TensorCategory\n",
    "    tls = TfmdLists(zip(img_paths, labels),\n",
    "                    tfms=[[PILImage.create], [CategoryEncode()]]) # No item_tfms here yet\n",
    "\n",
    "    # Apply item transforms to the input part (images)\n",
    "    tls = tls.map_tfms([item_tfms, None], dl_type=Datasets) # None means no tfms for labels\n",
    "\n",
    "\n",
    "    # 4. Create DataLoader\n",
    "    # `after_item` applies transforms to individual items after they are fetched\n",
    "    # `before_batch` applies transforms before collation\n",
    "    # `after_batch` applies transforms to the collated batch (like normalization)\n",
    "    dls = DataLoader(tls, bs=batch_size, num_workers=num_workers,\n",
    "                     after_item=[ToTensor], # Convert PILImage to Tensor\n",
    "                     after_batch=[IntToFloatTensor, batch_tfms], # Normalize batch\n",
    "                     shuffle=False, drop_last=False) # No shuffle/drop for validation\n",
    "\n",
    "    logger.info(f\"Created Zero-Shot DataLoader with {len(tls)} items.\")\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c64e93-8612-47e4-906a-549032560399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Placeholder for Retrieval DataLoader - Adapt from 04_data_creation if needed\n",
    "# This might be necessary if retrieval benchmarks have a different structure\n",
    "# or require specific test splits.\n",
    "\n",
    "# def create_retrieval_dataloader(...):\n",
    "#     logger.info(\"Retrieval DataLoader creation not fully implemented yet.\")\n",
    "#     # Reuse IndicCLIPDataBlock logic from 04_data_creation if applicable,\n",
    "#     # possibly filtering the source DataFrame for the specific benchmark and split.\n",
    "#     # Ensure shuffle=False and drop_last=False for evaluation.\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db69054-6f61-4d5a-b1c4-3898244759d9",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44884b88-2940-4d39-ab19-7384721df26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Example: Load data and create a Zero-Shot DataLoader\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Running Evaluation Benchmark Setup Example ---\")\n",
    "\n",
    "    # 1. Define benchmark specifics\n",
    "    benchmark_name = \"dummy_zeroshot_benchmark\" # Replace with actual benchmark name\n",
    "    benchmark_path = BENCHMARK_DATA_PATH\n",
    "    ensure_dir(benchmark_path / benchmark_name)\n",
    "\n",
    "    # 2. Create dummy benchmark data file (CSV example)\n",
    "    dummy_csv_path = benchmark_path / benchmark_name / f\"{benchmark_name}.csv\"\n",
    "    dummy_data = {\n",
    "        'image_path': [f'images/img_{i}.jpg' for i in range(10)],\n",
    "        'label': [0, 1, 2, 0, 1, 2, 0, 1, 2, 0] # Labels are indices into class_names\n",
    "    }\n",
    "    pd.DataFrame(dummy_data).to_csv(dummy_csv_path, index=False)\n",
    "    print(f\"Created dummy benchmark CSV: {dummy_csv_path}\")\n",
    "    # Create dummy image directory and files\n",
    "    dummy_image_dir = benchmark_path / benchmark_name / 'images'\n",
    "    ensure_dir(dummy_image_dir)\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            img = Image.new('RGB', (60, 30), color = 'red') # Create small dummy images\n",
    "            img.save(dummy_image_dir / f'img_{i}.jpg')\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating dummy image {i}: {e}\")\n",
    "    print(f\"Created dummy image files in: {dummy_image_dir}\")\n",
    "\n",
    "    # 3. Load the benchmark data\n",
    "    df_benchmark = load_benchmark_data(benchmark_name, benchmark_path)\n",
    "\n",
    "    if df_benchmark is not None:\n",
    "        print(f\"\\nLoaded benchmark data:\\n{df_benchmark.head()}\")\n",
    "\n",
    "        # 4. Define class names for this benchmark\n",
    "        class_names = [\"class_a\", \"class_b\", \"class_c\"] # Must match the labels in the data\n",
    "\n",
    "        # 5. Create Zero-Shot DataLoader\n",
    "        zs_dl = create_zeroshot_dataloader(\n",
    "            df=df_benchmark,\n",
    "            benchmark_base_path=(benchmark_path / benchmark_name), # Path where images are relative to\n",
    "            batch_size=4,\n",
    "            num_workers=0 # Use 0 for debugging ease\n",
    "        )\n",
    "\n",
    "        if zs_dl:\n",
    "            print(f\"\\nSuccessfully created Zero-Shot DataLoader.\")\n",
    "            # Inspect a batch\n",
    "            print(\"Inspecting one batch from Zero-Shot DataLoader:\")\n",
    "            batch = zs_dl.one_batch()\n",
    "            if isinstance(batch, tuple) and len(batch) == 2:\n",
    "                img_batch, lbl_batch = batch\n",
    "                print(f\"  Image Batch Shape: {img_batch.shape}\")\n",
    "                print(f\"  Label Batch Shape: {lbl_batch.shape}\")\n",
    "                print(f\"  Label Batch Values: {lbl_batch}\")\n",
    "                assert img_batch.ndim == 4\n",
    "                assert lbl_batch.ndim == 1\n",
    "            else:\n",
    "                print(f\"Unexpected batch format: {type(batch)}\")\n",
    "        else:\n",
    "            print(\"\\nFailed to create Zero-Shot DataLoader.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nFailed to load benchmark data for '{benchmark_name}'.\")\n",
    "\n",
    "    # Clean up dummy files (optional)\n",
    "    # import shutil\n",
    "    # if (benchmark_path / benchmark_name).exists():\n",
    "    #     shutil.rmtree(benchmark_path / benchmark_name)\n",
    "    #     print(f\"\\nCleaned up dummy benchmark directory: {benchmark_path / benchmark_name}\")\n",
    "\n",
    "    print(\"\\n--- Example Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d274a0-ff5b-47a6-a26c-0a9f8778d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # Run this in terminal to export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}