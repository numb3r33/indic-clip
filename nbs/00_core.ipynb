{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Utilities\n",
    "\n",
    "> Basic utilities, constants, and shared functions for the Indic-CLIP project. Adapted for potential Colab usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.19 requires fastcore<1.8,>=1.5.29, but you have fastcore 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# Note: nbdev install might be needed if running nbdev commands\n",
    "!pip install -q nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def setup_logging(level=logging.INFO):\n",
    "    \"\"\"Configures basic logging for the project.\"\"\"\n",
    "    # Remove existing handlers if any to avoid duplicate logs in interactive environments\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        # stream=sys.stdout # Ensure logs go to stdout, useful in Colab\n",
    "    )\n",
    "\n",
    "def get_logger(name):\n",
    "    \"\"\"Returns a logger instance.\"\"\"\n",
    "    return logging.getLogger(name)\n",
    "\n",
    "def ensure_dir(path: Path):\n",
    "    \"\"\"Ensure a directory exists, creating it if necessary.\"\"\"\n",
    "    path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Google Drive detected, setting PROJECT_ROOT to /content/drive/MyDrive/Indic-Clip\n",
      "Ensure your project files are located there.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# --- Project Root (Colab compatibility) ---\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Assume project is cloned into /content/Indic-Clip or Drive is mounted\n",
    "    # If using Drive, adjust this path accordingly e.g., Path('/content/drive/MyDrive/Indic-Clip')\n",
    "    # Check if Google Drive is mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    if Path('/content/drive/MyDrive').exists():\n",
    "       DEFAULT_ROOT = Path('/content/drive/MyDrive/Indic-Clip')\n",
    "       print(\"Google Drive detected, setting PROJECT_ROOT to /content/drive/MyDrive/Indic-Clip\")\n",
    "       print(\"Ensure your project files are located there.\")\n",
    "    else:\n",
    "       DEFAULT_ROOT = Path('/content/Indic-Clip')\n",
    "       print(\"Google Drive not detected. Setting PROJECT_ROOT to /content/Indic-Clip\")\n",
    "       print(\"Ensure your project files are located there (e.g., via !git clone).\")\n",
    "else:\n",
    "    # Default for local execution: use env var or parent of current dir\n",
    "    DEFAULT_ROOT = Path(os.getenv(\"INDIC_CLIP_ROOT\", default=Path.cwd()))\n",
    "    if DEFAULT_ROOT.name == 'nbs':\n",
    "        DEFAULT_ROOT = DEFAULT_ROOT.parent\n",
    "\n",
    "PROJECT_ROOT = DEFAULT_ROOT\n",
    "\n",
    "# --- Data Paths ---\n",
    "DATA_PATH = PROJECT_ROOT / 'data'\n",
    "RAW_DATA_PATH = DATA_PATH / 'raw'\n",
    "HINDI_RAW_PATH = RAW_DATA_PATH / 'hindi'\n",
    "SANSKRIT_RAW_PATH = RAW_DATA_PATH / 'sanskrit' # Placeholder\n",
    "SYNTHETIC_RAW_PATH = RAW_DATA_PATH / 'synthetic' # Placeholder\n",
    "PROCESSED_DATA_PATH = DATA_PATH / 'processed'\n",
    "BENCHMARK_DATA_PATH = DATA_PATH / 'benchmarks'\n",
    "\n",
    "# --- Model Paths ---\n",
    "MODEL_PATH = PROJECT_ROOT / 'models'\n",
    "CHECKPOINT_PATH = MODEL_PATH / 'checkpoints'\n",
    "ONNX_PATH = MODEL_PATH / 'onnx'\n",
    "QUANTIZED_PATH = MODEL_PATH / 'quantized'\n",
    "\n",
    "# --- Tokenizer Info ---\n",
    "# We are using a pre-trained tokenizer from Hugging Face\n",
    "PRETRAINED_TOKENIZER_NAME = \"ai4bharat/indic-bert\"\n",
    "TOKENIZER_PATH = MODEL_PATH / 'tokenizer' # Directory to save tokenizer config if needed\n",
    "\n",
    "# --- Special Tokens (Check compatibility with pre-trained tokenizer) ---\n",
    "# Standard tokens handled by HF tokenizer: [PAD], [UNK], [CLS], [SEP], [MASK]\n",
    "PAD_TOKEN = \"[PAD]\" # Typically handled by HF Tokenizer config\n",
    "UNK_TOKEN = \"[UNK]\" # Typically handled by HF Tokenizer config\n",
    "CLS_TOKEN = \"[CLS]\" # Typically handled by HF Tokenizer config\n",
    "SEP_TOKEN = \"[SEP]\" # Typically handled by HF Tokenizer config\n",
    "MASK_TOKEN = \"[MASK]\" # Typically handled by HF Tokenizer config\n",
    "\n",
    "# Custom language tokens (May need to be added to HF tokenizer vocabulary manually if used)\n",
    "# IndicBERT might implicitly handle language via context or specific training.\n",
    "# Check if these are strictly necessary for the chosen architecture.\n",
    "SANSKRIT_TOKEN = \"<Sa>\"\n",
    "HINDI_TOKEN = \"<Hi>\"\n",
    "\n",
    "# List of *custom* special tokens potentially needing addition\n",
    "CUSTOM_SPECIAL_TOKENS = [SANSKRIT_TOKEN, HINDI_TOKEN]\n",
    "\n",
    "# --- Default Values ---\n",
    "DEFAULT_IMAGE_SIZE = 224\n",
    "DEFAULT_BATCH_SIZE = 64 # Adjust based on GPU memory (especially in Colab)\n",
    "# DEFAULT_VOCAB_SIZE = 32000 # No longer needed, vocab size determined by pre-trained tokenizer\n",
    "DEFAULT_EMBED_DIM = 768     # Default for IndicBERT base, adjust if using a different text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 12:57:33 - __main__ - INFO - Running in Colab: True\n",
      "2025-04-17 12:57:33 - __main__ - INFO - Project Root: /content/drive/MyDrive/Indic-Clip\n",
      "2025-04-17 12:57:33 - __main__ - INFO - Ensuring essential directories exist...\n",
      "2025-04-17 12:57:34 - __main__ - INFO - Directory check complete.\n",
      "2025-04-17 12:57:34 - __main__ - INFO - Data Path: /content/drive/MyDrive/Indic-Clip/data\n",
      "2025-04-17 12:57:34 - __main__ - INFO - Model Path: /content/drive/MyDrive/Indic-Clip/models\n",
      "2025-04-17 12:57:34 - __main__ - INFO - Tokenizer Name: ai4bharat/indic-bert\n",
      "2025-04-17 12:57:34 - __main__ - INFO - Custom Special Tokens: ['<Sa>', '<Hi>']\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# Example Usage & Directory Creation (remove or comment out in final export if not needed)\n",
    "if __name__ == '__main__':\n",
    "    setup_logging()\n",
    "    logger = get_logger(__name__)\n",
    "    logger.info(f\"Running in Colab: {IN_COLAB}\")\n",
    "    logger.info(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "    # Create essential directories\n",
    "    logger.info(\"Ensuring essential directories exist...\")\n",
    "    ensure_dir(DATA_PATH)\n",
    "    ensure_dir(RAW_DATA_PATH)\n",
    "    ensure_dir(HINDI_RAW_PATH)\n",
    "    ensure_dir(SANSKRIT_RAW_PATH)\n",
    "    ensure_dir(SYNTHETIC_RAW_PATH)\n",
    "    ensure_dir(PROCESSED_DATA_PATH)\n",
    "    ensure_dir(BENCHMARK_DATA_PATH)\n",
    "    ensure_dir(MODEL_PATH)\n",
    "    ensure_dir(CHECKPOINT_PATH)\n",
    "    ensure_dir(ONNX_PATH)\n",
    "    ensure_dir(QUANTIZED_PATH)\n",
    "    ensure_dir(TOKENIZER_PATH)\n",
    "    logger.info(\"Directory check complete.\")\n",
    "\n",
    "    logger.info(f\"Data Path: {DATA_PATH}\")\n",
    "    logger.info(f\"Model Path: {MODEL_PATH}\")\n",
    "    logger.info(f\"Tokenizer Name: {PRETRAINED_TOKENIZER_NAME}\")\n",
    "    logger.info(f\"Custom Special Tokens: {CUSTOM_SPECIAL_TOKENS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Indic-Clip\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Indic-Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Trigger export\n",
    "import nbdev;\n",
    "nbdev.nbdev_export() # Run this manually in terminal after editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
